{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\past\\types\\oldstr.py:33: DeprecationWarning: invalid escape sequence \\d\n",
      "  \"\"\"\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pprint import pprint\n",
    "import gensim\n",
    "import gensim.corpora as corpora\n",
    "from gensim.utils import simple_preprocess\n",
    "from gensim.models import CoherenceModel\n",
    "import spacy\n",
    "import pyLDAvis\n",
    "import pyLDAvis.gensim\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\",category=DeprecationWarning)\n",
    "import pickle\n",
    "from nltk.corpus import stopwords\n",
    "stop_words = stopwords.words('english')\n",
    "from nltk.stem import WordNetLemmatizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('abcnews-date-text.csv', error_bad_lines =False)\n",
    "data['publish_date'] = pd.to_datetime(data['publish_date'].astype(str), format = '%Y%m%d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['publish_date'] = pd.DatetimeIndex(data['publish_date']).year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sent_to_words(sentences):\n",
    "    for sentence in sentences:\n",
    "        yield(gensim.utils.simple_preprocess(str(sentence), deacc=True))  # deacc=True removes punctuations\n",
    "\n",
    "data_words = list(sent_to_words(data['headline_text']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define functions for stopwords, bigrams, trigrams and lemmatization\n",
    "def remove_stopwords(texts):\n",
    "    return [[word for word in simple_preprocess(str(doc)) if word not in stop_words] for doc in texts]\n",
    "\n",
    "def lemmatization(texts, allowed_postags=['NOUN', 'ADJ', 'VERB', 'ADV']):\n",
    "    \"\"\"https://spacy.io/api/annotation\"\"\"\n",
    "    texts_out = []\n",
    "    for sent in texts:\n",
    "        doc = nlp(\" \".join(sent)) \n",
    "        texts_out.append([token.lemma_ for token in doc if token.pos_ in allowed_postags])\n",
    "    return texts_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove Stop Words\n",
    "data_words_nostops = remove_stopwords(data_words)\n",
    "data_words_nostops = pd.Series(data_words_nostops)\n",
    "data_lemmatized = data_words_nostops.apply(lambda x: [WordNetLemmatizer().lemmatize(word, pos='v') for word in x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = data\n",
    "temp['lemmatize'] = data_lemmatized\n",
    "for i in range(15):\n",
    "    globals()['trend{}'.format(i+2003)] = temp.loc[temp.publish_date == i+2003]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "trend_list = [trend2003, trend2004, trend2005, trend2006, trend2007, trend2008, trend2009, trend2010, trend2011, trend2012, trend2013, trend2014, trend2015, trend2016, trend2017]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmatized = list(trend2015['lemmatize'])\n",
    "id2word = corpora.Dictionary(lemmatized)\n",
    "texts = lemmatized\n",
    "corpus = [id2word.doc2bow(text) for text in texts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build LDA model\n",
    "lda_model = gensim.models.ldamodel.LdaModel(corpus=corpus,\n",
    "                                           id2word=id2word,\n",
    "                                           num_topics=20, \n",
    "                                           random_state=100,\n",
    "                                           update_every=1,\n",
    "                                           chunksize=100,\n",
    "                                           passes=10,\n",
    "                                           alpha='auto',\n",
    "                                           per_word_topics=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Perplexity:  -25.65348551907308\n",
      "\n",
      "Coherence Score:  0.4240479090789065\n"
     ]
    }
   ],
   "source": [
    "# Compute Perplexity\n",
    "print('\\nPerplexity: ', lda_model.log_perplexity(corpus))  # a measure of how good the model is. lower the better.\n",
    "\n",
    "# Compute Coherence Score\n",
    "coherence_model_lda = CoherenceModel(model=lda_model, texts=lemmatized, dictionary=id2word, coherence='c_v')\n",
    "coherence_lda = coherence_model_lda.get_coherence()\n",
    "print('\\nCoherence Score: ', coherence_lda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0,\n",
      "  '0.162*\"australian\" + 0.146*\"call\" + 0.109*\"melbourne\" + 0.077*\"price\" + '\n",
      "  '0.051*\"western\" + 0.046*\"high\" + 0.044*\"victoria\" + 0.043*\"four\" + '\n",
      "  '0.033*\"prepare\" + 0.031*\"girl\"'),\n",
      " (1,\n",
      "  '0.125*\"attack\" + 0.112*\"back\" + 0.108*\"mine\" + 0.062*\"deal\" + 0.059*\"fan\" + '\n",
      "  '0.057*\"celebrate\" + 0.049*\"target\" + 0.041*\"hill\" + 0.037*\"party\" + '\n",
      "  '0.033*\"reveal\"'),\n",
      " (2,\n",
      "  '0.290*\"fire\" + 0.136*\"nsw\" + 0.130*\"hobart\" + 0.114*\"rural\" + 0.072*\"world\" '\n",
      "  '+ 0.036*\"boat\" + 0.032*\"turn\" + 0.013*\"flight\" + 0.011*\"around\" + '\n",
      "  '0.006*\"well\"'),\n",
      " (3,\n",
      "  '0.285*\"country\" + 0.256*\"hour\" + 0.100*\"podcast\" + 0.033*\"leaders\" + '\n",
      "  '0.030*\"thursday\" + 0.019*\"abbott\" + 0.018*\"tony\" + 0.014*\"policy\" + '\n",
      "  '0.012*\"agricultural\" + 0.009*\"shorten\"'),\n",
      " (4,\n",
      "  '0.307*\"new\" + 0.220*\"year\" + 0.076*\"force\" + 0.074*\"fall\" + 0.063*\"dead\" + '\n",
      "  '0.044*\"tas\" + 0.028*\"farmer\" + 0.017*\"fruit\" + 0.008*\"philippines\" + '\n",
      "  '0.007*\"injury\"'),\n",
      " (5,\n",
      "  '0.286*\"qld\" + 0.182*\"release\" + 0.002*\"paper\" + 0.000*\"north\" + '\n",
      "  '0.000*\"west\" + 0.000*\"christmas\" + 0.000*\"wild\" + 0.000*\"government\" + '\n",
      "  '0.000*\"drought\" + 0.000*\"union\"'),\n",
      " (6,\n",
      "  '0.124*\"take\" + 0.103*\"box\" + 0.094*\"could\" + 0.080*\"break\" + 0.069*\"search\" '\n",
      "  '+ 0.053*\"black\" + 0.045*\"thousands\" + 0.033*\"alert\" + 0.031*\"laws\" + '\n",
      "  '0.024*\"week\"'),\n",
      " (7,\n",
      "  '0.271*\"police\" + 0.222*\"say\" + 0.083*\"open\" + 0.071*\"dog\" + 0.068*\"go\" + '\n",
      "  '0.026*\"welcome\" + 0.024*\"president\" + 0.023*\"announce\" + 0.014*\"level\" + '\n",
      "  '0.012*\"allow\"'),\n",
      " (8,\n",
      "  '0.087*\"court\" + 0.081*\"home\" + 0.077*\"council\" + 0.071*\"hunter\" + '\n",
      "  '0.065*\"help\" + 0.054*\"time\" + 0.045*\"injure\" + 0.045*\"national\" + '\n",
      "  '0.036*\"build\" + 0.034*\"end\"'),\n",
      " (9,\n",
      "  '0.204*\"south\" + 0.102*\"china\" + 0.083*\"talk\" + 0.060*\"appeal\" + '\n",
      "  '0.052*\"labor\" + 0.044*\"plant\" + 0.037*\"peter\" + 0.034*\"allegedly\" + '\n",
      "  '0.033*\"begin\" + 0.031*\"try\"'),\n",
      " (10,\n",
      "  '0.149*\"queensland\" + 0.117*\"kill\" + 0.111*\"crash\" + 0.090*\"road\" + '\n",
      "  '0.089*\"record\" + 0.086*\"nt\" + 0.079*\"hit\" + 0.026*\"plane\" + 0.022*\"toll\" + '\n",
      "  '0.021*\"suspend\"'),\n",
      " (11,\n",
      "  '0.178*\"find\" + 0.111*\"two\" + 0.105*\"adelaide\" + 0.097*\"murder\" + '\n",
      "  '0.084*\"first\" + 0.069*\"make\" + 0.031*\"body\" + 0.028*\"probe\" + '\n",
      "  '0.024*\"outback\" + 0.024*\"tourism\"'),\n",
      " (12,\n",
      "  '0.340*\"australia\" + 0.150*\"league\" + 0.117*\"live\" + 0.038*\"launch\" + '\n",
      "  '0.024*\"campaign\" + 0.019*\"benefit\" + 0.014*\"update\" + 0.012*\"stream\" + '\n",
      "  '0.010*\"cabinet\" + 0.009*\"document\"'),\n",
      " (13,\n",
      "  '0.233*\"test\" + 0.135*\"drug\" + 0.111*\"brisbane\" + 0.052*\"international\" + '\n",
      "  '0.046*\"british\" + 0.041*\"double\" + 0.028*\"treat\" + 0.013*\"patient\" + '\n",
      "  '0.012*\"ebola\" + 0.000*\"west\"'),\n",
      " (14,\n",
      "  '0.399*\"wa\" + 0.142*\"bushfire\" + 0.039*\"research\" + 0.034*\"expansion\" + '\n",
      "  '0.025*\"ready\" + 0.000*\"december\" + 0.000*\"government\" + 0.000*\"warn\" + '\n",
      "  '0.000*\"federal\" + 0.000*\"internet\"'),\n",
      " (15,\n",
      "  '0.059*\"fee\" + 0.000*\"waive\" + 0.000*\"landfill\" + 0.000*\"christmas\" + '\n",
      "  '0.000*\"residents\" + 0.000*\"otway\" + 0.000*\"victims\" + 0.000*\"pinery\" + '\n",
      "  '0.000*\"respite\" + 0.000*\"offer\"'),\n",
      " (16,\n",
      "  '0.156*\"sa\" + 0.076*\"miss\" + 0.075*\"one\" + 0.068*\"die\" + 0.055*\"use\" + '\n",
      "  '0.052*\"three\" + 0.052*\"darwin\" + 0.042*\"vic\" + 0.038*\"number\" + '\n",
      "  '0.032*\"may\"'),\n",
      " (17,\n",
      "  '0.326*\"man\" + 0.109*\"perth\" + 0.089*\"flood\" + 0.052*\"people\" + '\n",
      "  '0.037*\"prison\" + 0.034*\"still\" + 0.028*\"supply\" + 0.026*\"siege\" + '\n",
      "  '0.025*\"spark\" + 0.024*\"summer\"'),\n",
      " (18,\n",
      "  '0.233*\"water\" + 0.182*\"arrest\" + 0.032*\"access\" + 0.017*\"member\" + '\n",
      "  '0.000*\"sydney\" + 0.000*\"child\" + 0.000*\"woman\" + 0.000*\"close\" + '\n",
      "  '0.000*\"crime\" + 0.000*\"drought\"'),\n",
      " (19,\n",
      "  '0.245*\"day\" + 0.167*\"years\" + 0.087*\"show\" + 0.064*\"teen\" + 0.047*\"heat\" + '\n",
      "  '0.043*\"sport\" + 0.038*\"issue\" + 0.028*\"free\" + 0.023*\"australias\" + '\n",
      "  '0.018*\"asbestos\"')]\n"
     ]
    }
   ],
   "source": [
    "# Print the Keyword in the 10 topics\n",
    "pprint(lda_model.print_topics())\n",
    "doc_lda = lda_model[corpus]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
