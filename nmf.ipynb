{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd;\n",
    "import numpy as np;\n",
    "import scipy as sp;\n",
    "import sklearn;\n",
    "import sys;\n",
    "from nltk.corpus import stopwords;\n",
    "import nltk;\n",
    "from gensim.models import ldamodel\n",
    "import gensim.corpora;\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer;\n",
    "from sklearn.decomposition import NMF;\n",
    "from sklearn.preprocessing import normalize;\n",
    "import pickle;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('C:\\\\Users\\\\kdwoo\\\\Documents\\\\Jupyter\\\\2019_CAU_NLP\\\\abcnews-date-text.csv', error_bad_lines=False);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         publish_date\n",
      "0            20030219\n",
      "1            20030219\n",
      "2            20030219\n",
      "3            20030219\n",
      "4            20030219\n",
      "5            20030219\n",
      "6            20030219\n",
      "7            20030219\n",
      "8            20030219\n",
      "9            20030219\n",
      "10           20030219\n",
      "11           20030219\n",
      "12           20030219\n",
      "13           20030219\n",
      "14           20030219\n",
      "15           20030219\n",
      "16           20030219\n",
      "17           20030219\n",
      "18           20030219\n",
      "19           20030219\n",
      "20           20030219\n",
      "21           20030219\n",
      "22           20030219\n",
      "23           20030219\n",
      "24           20030219\n",
      "25           20030219\n",
      "26           20030219\n",
      "27           20030219\n",
      "28           20030219\n",
      "29           20030219\n",
      "...               ...\n",
      "1103633      20171231\n",
      "1103634      20171231\n",
      "1103635      20171231\n",
      "1103636      20171231\n",
      "1103637      20171231\n",
      "1103638      20171231\n",
      "1103639      20171231\n",
      "1103640      20171231\n",
      "1103641      20171231\n",
      "1103642      20171231\n",
      "1103643      20171231\n",
      "1103644      20171231\n",
      "1103645      20171231\n",
      "1103646      20171231\n",
      "1103647      20171231\n",
      "1103648      20171231\n",
      "1103649      20171231\n",
      "1103650      20171231\n",
      "1103651      20171231\n",
      "1103652      20171231\n",
      "1103653      20171231\n",
      "1103654      20171231\n",
      "1103655      20171231\n",
      "1103656      20171231\n",
      "1103657      20171231\n",
      "1103658      20171231\n",
      "1103659      20171231\n",
      "1103660      20171231\n",
      "1103661      20171231\n",
      "1103662      20171231\n",
      "\n",
      "[1103663 rows x 1 columns]\n"
     ]
    }
   ],
   "source": [
    "data_text = data[['headline_text']];\n",
    "data_date = data[['publish_date']];\n",
    "\n",
    "print(data_date);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_text = data_text.astype('str');\n",
    "data_date = data_date.astype('str');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# import nltk\n",
    "# nltk.download('stopwords')\n",
    " \n",
    "for idx in range(len(data_text)):\n",
    "    # Input Year\n",
    "    if int(data_date.iloc[idx]['publish_date']) // 10000 < 2004:\n",
    "        continue;\n",
    "    if int(data_date.iloc[idx]['publish_date']) // 10000 == 2004:\n",
    "        data_text.iloc[idx]['headline_text'] = [word for word in data_text.iloc[idx]['headline_text'].split(' ') if word not in stopwords.words()];\n",
    "\n",
    "    elif int(data_date.iloc[idx]['publish_date']) // 10000 > 2004:\n",
    "        break;\n",
    "        \n",
    "    if idx % 1000 == 0:\n",
    "        sys.stdout.write('\\rc = ' + str(idx) + ' / ' + str(len(data_text)));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(data_text, open('2003_data_text.dat', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['aba', 'decides', 'community', 'broadcasting', 'licence']\n"
     ]
    }
   ],
   "source": [
    "train_headlines = [value[0] for value in data_text.iloc[0:].values];\n",
    "print(train_headlines[0]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_topics = 10;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aba decides community broadcasting licence\n"
     ]
    }
   ],
   "source": [
    "train_headlines_sentences = [' '.join(text) for text in train_headlines]\n",
    "print(train_headlines_sentences[0]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer(analyzer='word', max_features=5000);\n",
    "x_counts = vectorizer.fit_transform(train_headlines_sentences);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformer = TfidfTransformer(smooth_idf=False);\n",
    "x_tfidf = transformer.fit_transform(x_counts);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "xtfidf_norm = normalize(x_tfidf, norm='l1', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "#obtain a NMF model.\n",
    "model = NMF(n_components=num_topics, init='nndsvd');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NMF(alpha=0.0, beta_loss='frobenius', init='nndsvd', l1_ratio=0.0,\n",
       "  max_iter=200, n_components=8, random_state=None, shuffle=False,\n",
       "  solver='cd', tol=0.0001, verbose=0)"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#fit the model\n",
    "model.fit(xtfidf_norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_nmf_topics(model, n_top_words):\n",
    "    \n",
    "    #the word ids obtained need to be reverse-mapped to the words so we can print the topic names.\n",
    "    feat_names = vectorizer.get_feature_names()\n",
    "    \n",
    "    word_dict = {};\n",
    "    for i in range(num_topics):\n",
    "        \n",
    "        #for each topic, obtain the largest values, and add the words they map to into the dictionary.\n",
    "        words_ids = model.components_[i].argsort()[:-20 - 1:-1]\n",
    "        words = [feat_names[key] for key in words_ids]\n",
    "        word_dict['Topic # ' + '{:02d}'.format(i+1)] = words;\n",
    "    \n",
    "    return pd.DataFrame(word_dict);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Topic # 01</th>\n",
       "      <th>Topic # 02</th>\n",
       "      <th>Topic # 03</th>\n",
       "      <th>Topic # 04</th>\n",
       "      <th>Topic # 05</th>\n",
       "      <th>Topic # 06</th>\n",
       "      <th>Topic # 07</th>\n",
       "      <th>Topic # 08</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>police</td>\n",
       "      <td>us</td>\n",
       "      <td>new</td>\n",
       "      <td>govt</td>\n",
       "      <td>council</td>\n",
       "      <td>court</td>\n",
       "      <td>iraq</td>\n",
       "      <td>plan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>probe</td>\n",
       "      <td>iraqi</td>\n",
       "      <td>zealand</td>\n",
       "      <td>urged</td>\n",
       "      <td>considers</td>\n",
       "      <td>murder</td>\n",
       "      <td>says</td>\n",
       "      <td>water</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>investigate</td>\n",
       "      <td>baghdad</td>\n",
       "      <td>laws</td>\n",
       "      <td>nsw</td>\n",
       "      <td>water</td>\n",
       "      <td>charges</td>\n",
       "      <td>killed</td>\n",
       "      <td>fire</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>missing</td>\n",
       "      <td>troops</td>\n",
       "      <td>hospital</td>\n",
       "      <td>vic</td>\n",
       "      <td>rejects</td>\n",
       "      <td>charged</td>\n",
       "      <td>crash</td>\n",
       "      <td>back</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>search</td>\n",
       "      <td>open</td>\n",
       "      <td>chief</td>\n",
       "      <td>wa</td>\n",
       "      <td>backs</td>\n",
       "      <td>faces</td>\n",
       "      <td>troops</td>\n",
       "      <td>call</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>death</td>\n",
       "      <td>soldier</td>\n",
       "      <td>president</td>\n",
       "      <td>qld</td>\n",
       "      <td>land</td>\n",
       "      <td>charge</td>\n",
       "      <td>report</td>\n",
       "      <td>group</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>crash</td>\n",
       "      <td>killed</td>\n",
       "      <td>home</td>\n",
       "      <td>boost</td>\n",
       "      <td>seeks</td>\n",
       "      <td>front</td>\n",
       "      <td>car</td>\n",
       "      <td>support</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>car</td>\n",
       "      <td>forces</td>\n",
       "      <td>centre</td>\n",
       "      <td>funding</td>\n",
       "      <td>funds</td>\n",
       "      <td>hears</td>\n",
       "      <td>two</td>\n",
       "      <td>health</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>hunt</td>\n",
       "      <td>fallujah</td>\n",
       "      <td>record</td>\n",
       "      <td>claims</td>\n",
       "      <td>development</td>\n",
       "      <td>woman</td>\n",
       "      <td>bush</td>\n",
       "      <td>boost</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>shooting</td>\n",
       "      <td>military</td>\n",
       "      <td>deal</td>\n",
       "      <td>funds</td>\n",
       "      <td>merger</td>\n",
       "      <td>drug</td>\n",
       "      <td>pm</td>\n",
       "      <td>public</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>fatal</td>\n",
       "      <td>attack</td>\n",
       "      <td>set</td>\n",
       "      <td>accused</td>\n",
       "      <td>claims</td>\n",
       "      <td>trial</td>\n",
       "      <td>howard</td>\n",
       "      <td>backs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>seek</td>\n",
       "      <td>soldiers</td>\n",
       "      <td>year</td>\n",
       "      <td>fire</td>\n",
       "      <td>decision</td>\n",
       "      <td>death</td>\n",
       "      <td>attack</td>\n",
       "      <td>says</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>murder</td>\n",
       "      <td>korea</td>\n",
       "      <td>get</td>\n",
       "      <td>report</td>\n",
       "      <td>consider</td>\n",
       "      <td>case</td>\n",
       "      <td>soldiers</td>\n",
       "      <td>residents</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>road</td>\n",
       "      <td>dollar</td>\n",
       "      <td>mayor</td>\n",
       "      <td>act</td>\n",
       "      <td>budget</td>\n",
       "      <td>appeal</td>\n",
       "      <td>three</td>\n",
       "      <td>power</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>sydney</td>\n",
       "      <td>trade</td>\n",
       "      <td>york</td>\n",
       "      <td>says</td>\n",
       "      <td>rise</td>\n",
       "      <td>told</td>\n",
       "      <td>dead</td>\n",
       "      <td>mp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>fire</td>\n",
       "      <td>talks</td>\n",
       "      <td>may</td>\n",
       "      <td>health</td>\n",
       "      <td>wants</td>\n",
       "      <td>sex</td>\n",
       "      <td>accident</td>\n",
       "      <td>hospital</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>arrest</td>\n",
       "      <td>deal</td>\n",
       "      <td>high</td>\n",
       "      <td>local</td>\n",
       "      <td>plans</td>\n",
       "      <td>high</td>\n",
       "      <td>blair</td>\n",
       "      <td>concerns</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>drug</td>\n",
       "      <td>sanctions</td>\n",
       "      <td>gets</td>\n",
       "      <td>fed</td>\n",
       "      <td>approves</td>\n",
       "      <td>stabbing</td>\n",
       "      <td>injured</td>\n",
       "      <td>restrictions</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>attack</td>\n",
       "      <td>iran</td>\n",
       "      <td>pm</td>\n",
       "      <td>call</td>\n",
       "      <td>mayor</td>\n",
       "      <td>assault</td>\n",
       "      <td>found</td>\n",
       "      <td>sought</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>stabbing</td>\n",
       "      <td>australia</td>\n",
       "      <td>england</td>\n",
       "      <td>tas</td>\n",
       "      <td>security</td>\n",
       "      <td>accused</td>\n",
       "      <td>bomb</td>\n",
       "      <td>development</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Topic # 01 Topic # 02 Topic # 03 Topic # 04   Topic # 05 Topic # 06  \\\n",
       "0        police         us        new       govt      council      court   \n",
       "1         probe      iraqi    zealand      urged    considers     murder   \n",
       "2   investigate    baghdad       laws        nsw        water    charges   \n",
       "3       missing     troops   hospital        vic      rejects    charged   \n",
       "4        search       open      chief         wa        backs      faces   \n",
       "5         death    soldier  president        qld         land     charge   \n",
       "6         crash     killed       home      boost        seeks      front   \n",
       "7           car     forces     centre    funding        funds      hears   \n",
       "8          hunt   fallujah     record     claims  development      woman   \n",
       "9      shooting   military       deal      funds       merger       drug   \n",
       "10        fatal     attack        set    accused       claims      trial   \n",
       "11         seek   soldiers       year       fire     decision      death   \n",
       "12       murder      korea        get     report     consider       case   \n",
       "13         road     dollar      mayor        act       budget     appeal   \n",
       "14       sydney      trade       york       says         rise       told   \n",
       "15         fire      talks        may     health        wants        sex   \n",
       "16       arrest       deal       high      local        plans       high   \n",
       "17         drug  sanctions       gets        fed     approves   stabbing   \n",
       "18       attack       iran         pm       call        mayor    assault   \n",
       "19     stabbing  australia    england        tas     security    accused   \n",
       "\n",
       "   Topic # 07    Topic # 08  \n",
       "0        iraq          plan  \n",
       "1        says         water  \n",
       "2      killed          fire  \n",
       "3       crash          back  \n",
       "4      troops          call  \n",
       "5      report         group  \n",
       "6         car       support  \n",
       "7         two        health  \n",
       "8        bush         boost  \n",
       "9          pm        public  \n",
       "10     howard         backs  \n",
       "11     attack          says  \n",
       "12   soldiers     residents  \n",
       "13      three         power  \n",
       "14       dead            mp  \n",
       "15   accident      hospital  \n",
       "16      blair      concerns  \n",
       "17    injured  restrictions  \n",
       "18      found        sought  \n",
       "19       bomb   development  "
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_nmf_topics(model, 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
